{
  "cells": [
    {
      "cell_type": "markdown",
      "source": "Contains information from [Kaggle](https://www.kaggle.com/soroushghaderi/chocolate-bar-2020) which is made available\nunder the ODC Attribution License.",
      "metadata": {
        "tags": [],
        "cell_id": "00001-d2e66013-ef84-410f-adaf-2936230df48e",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00000-018398f4-d7f1-497f-85b6-bb0f40868eb3",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "6a7723e2",
        "execution_millis": 1786,
        "execution_start": 1615576096812,
        "deepnote_cell_type": "code"
      },
      "source": "import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection    import train_test_split, RandomizedSearchCV\nfrom sklearn.linear_model       import Ridge\nfrom sklearn.ensemble           import RandomForestRegressor\nfrom sklearn.impute             import MissingIndicator, SimpleImputer\nfrom sklearn.metrics            import r2_score\nfrom sklearn.pipeline           import Pipeline\nfrom sklearn.preprocessing      import StandardScaler, OneHotEncoder\nfrom sklearn.compose            import ColumnTransformer\nfrom sklearn.feature_selection  import SelectFromModel\nfrom sklearn.inspection         import permutation_importance",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00001-c0982175-78c6-4872-b03c-83ae1efe22f7",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "c211c62a",
        "execution_millis": 18,
        "execution_start": 1615576098600,
        "deepnote_cell_type": "code"
      },
      "source": "chocolate_df = pd.read_csv('chocolate.csv', index_col='Unnamed: 0')",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00003-78f06398-c433-4110-93fc-9367ea396313",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "b00d8dc4",
        "execution_millis": 4,
        "execution_start": 1615576098623,
        "deepnote_cell_type": "code"
      },
      "source": "# 'ref' is the id of the taste test dropping it to avoid data leak\nX = chocolate_df.drop(['ref', 'rating'], axis=1)\ny = chocolate_df['rating']",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00002-2733a252-1dda-4de9-8504-a26d3820e54d",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "ed8471e7",
        "execution_millis": 4,
        "execution_start": 1615576098630,
        "deepnote_cell_type": "code"
      },
      "source": "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=10)",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "# Checking for missing values",
      "metadata": {
        "tags": [],
        "cell_id": "00005-901d2537-4d3c-48a3-b8ba-a38bbc52c80f",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00005-395a96a8-5e1c-4521-811b-464ac5c14f49",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "56bfa7e2",
        "execution_millis": 6,
        "execution_start": 1615577134025,
        "deepnote_cell_type": "code"
      },
      "source": "# Checking for missing data\nindicator = MissingIndicator(features=\"all\")\nmissing = indicator.fit_transform(X_train.values)\n# summing column wise to do a count of missing values for each columns\nmissing.sum(axis=0)",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 25,
          "data": {
            "text/plain": "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n          0,    0,    0,    0,   52,  452, 1482])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "So only the last 3 columns has missing values which are 2nd to 4th taste test. They are all categorical variables just imputing it as 'missing' because these taste test are optional.",
      "metadata": {
        "tags": [],
        "cell_id": "00005-5e8eb23c-4d63-493a-890a-a61015135a9c",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00006-61ccb0c0-14cd-45bc-bcb7-236d65c30a92",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "e86ad8de",
        "execution_millis": 5,
        "execution_start": 1615576100525,
        "deepnote_cell_type": "code"
      },
      "source": "indicator = MissingIndicator(features=\"all\")\nmissing = indicator.fit_transform(y_train.values.reshape(-1, 1))\nmissing.sum(axis=0)",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "array([0])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "there's no missing values in y",
      "metadata": {
        "tags": [],
        "cell_id": "00007-71527a92-ad06-421a-ba10-05a26d239ace",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": "# Model / Feature / Hyperparmeter Selection\nI am mainly interested in how `Ridge` and `RandomForestRegressor` differ in their performance on this data set. So I will be focusing on comparing these two models.",
      "metadata": {
        "tags": [],
        "cell_id": "00009-9d4b5522-5fab-41a2-a39f-b0e38075cb4b",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00010-fde4550b-3ce6-4f2c-aa73-a60406df19e8",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "304b3b64",
        "execution_millis": 2,
        "execution_start": 1615576103517,
        "deepnote_cell_type": "code"
      },
      "source": "# preprocessing pipeline set up\ncategorical_columns = (X_train.dtypes == object)\n# treating 'review_date' as categorical too because it's the year\ncategorical_columns['review_date'] = True\n\n# the preprocessing code used here are inspired by codes from class\ncon_pipe = Pipeline(\n    [\n        ('scaler', StandardScaler())\n    ]\n)\n\ncat_pipe = Pipeline(\n    [\n        (\n            'imputer',\n            SimpleImputer(\n                strategy='constant', fill_value='missing', add_indicator=True,\n            )\n        ),\n        (\n            'ohe',\n            OneHotEncoder(handle_unknown='ignore')\n        ),\n    ]\n)\n\npreprocessing = ColumnTransformer(\n    [\n        ('categorical', cat_pipe,  categorical_columns),\n        ('continuous',  con_pipe, ~categorical_columns),\n    ]\n)",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00010-adbffe3f-eef2-4b41-bf4a-bc5a5bded714",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "3b0963ba",
        "execution_millis": 30149,
        "output_cleared": false,
        "execution_start": 1615576654510,
        "deepnote_cell_type": "code"
      },
      "source": "# ridge\nsearch_space = {\n    # alpha is the penalty rate which determines\n    # how much we are restrciting the coeffcients by \n    'ridge__alpha': np.logspace(0, 4, 10),\n}\n\nridge_pipe = Pipeline(\n    [\n        ('preprocessing', preprocessing),\n        # log2 to reduce run time, otherwise it takes too long\n        # using select from model to do automatic feature selection\n        ('sfm', SelectFromModel(\n                RandomForestRegressor(max_features=\"log2\"),\n                # choosing 450 because it was a good balance point\n                # from my initial testing. Didn't put it as a hyper param\n                # here because it would take too long\n                max_features=450,\n            ),\n        ),\n        ('ridge', Ridge()),\n    ]\n)\n\nridge_rscv = RandomizedSearchCV(\n    ridge_pipe,\n    search_space,\n    n_jobs=-1,\n)\nridge_rscv.fit(X_train, y_train)\n\nclean_ridge_best_param = {\n    k.replace('ridge__', ''): v\n    for k, v in ridge_rscv.best_params_.items()   \n}\n\nprint(clean_ridge_best_param)\nprint('R^2: ', ridge_rscv.best_score_)",
      "execution_count": 11,
      "outputs": [
        {
          "name": "stdout",
          "text": "{'alpha': 2.7825594022071245}\nR^2:  0.3024424589293524\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00012-17461418-2107-41be-8c1e-cf52a791ab02",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "cdd48543",
        "execution_millis": 33006,
        "output_cleared": false,
        "execution_start": 1615576106727,
        "deepnote_cell_type": "code"
      },
      "source": "# random forest regressor\n# the structure of this basically repeats the previous cell\n# excep the search space\nsearch_space = {\n    # testing out n_estimators because too few trees could lead to a bad model\n    # but too many will also slow down the fitting\n    'rfr__n_estimators': [20, 50, 100, 150, 200],\n    # avoid each tree from becoming too specific,\n    # but also to reduce run time when fitting\n    'rfr__max_depth': range(1, 20, 2),\n    # avoid each tree from becoming too specific,\n    # but also to reduce run time when fitting\n    'rfr__min_samples_split': range(2, 10),\n    # limiting max feature help make the trees more independent\n    'rfr__max_features': [\"sqrt\", \"log2\"],\n    # avoid each tree from becoming too specific,\n    # but also to reduce run time when fitting\n    'rfr__min_samples_leaf': range(1, 50, 5),\n    # avoid each tree from becoming too specific,\n    # but also to reduce run time when fitting\n    'rfr__max_leaf_nodes': range(1, 100, 5),\n    # help trees become more independent by limiting the\n    # amount of data they see\n    'rfr__max_samples': [0.6, 0.8, 1],\n}\n\nrfr_pipe = Pipeline(\n    [\n        ('preprocessing', preprocessing),\n        ('sfm', SelectFromModel(\n                RandomForestRegressor(max_features=\"log2\"),\n                max_features=450,\n            )\n        ),\n        ('rfr', RandomForestRegressor()),\n    ]\n)\n\nrfr_rscv = RandomizedSearchCV(\n    rfr_pipe,\n    search_space,\n    n_jobs=-1,\n)\nrfr_rscv.fit(X_train, y_train)\n\nclean_rfr_best_param = {\n    k.replace('rfr__', ''): v\n    for k, v in rfr_rscv.best_params_.items()\n}\n\nprint(clean_rfr_best_param)\nprint('R^2: ', rfr_rscv.best_score_)",
      "execution_count": 9,
      "outputs": [
        {
          "name": "stdout",
          "text": "{'n_estimators': 20, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_samples': 0.8, 'max_leaf_nodes': 41, 'max_features': 'log2', 'max_depth': 13}\nR^2:  0.10775484982259846\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "My final model choice is `Ridge` since it did much better than random forest regressor in this case.\n\nThe model is `Ridge(alpha=2.7825594022071245)`",
      "metadata": {
        "tags": [],
        "cell_id": "00016-9b0eda00-93e0-4c61-bb12-dceeadc1d866",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": "# Final Model",
      "metadata": {
        "tags": [],
        "cell_id": "00014-8b20f95e-ecb1-4101-aa2d-0b0f61ce658e",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00016-ebd8832f-e949-4bcd-a5c8-edf5d6407e25",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "ebd285e",
        "execution_millis": 968,
        "execution_start": 1615576704109,
        "deepnote_cell_type": "code"
      },
      "source": "# fit final model\nsfm = ridge_rscv.best_estimator_.named_steps['sfm']\n\nfinal_ridge_pipe = Pipeline(\n    [\n        ('preprocessing', preprocessing),\n        ('sfm', sfm),\n        ('ridge', Ridge(alpha=2.7825594022071245)),\n    ]\n)\nfinal_ridge_pipe.fit(X_train, y_train)",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/plain": "Pipeline(steps=[('preprocessing',\n                 ColumnTransformer(transformers=[('categorical',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(add_indicator=True,\n                                                                                 fill_value='missing',\n                                                                                 strategy='constant')),\n                                                                  ('ohe',\n                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n                                                  company                              True\ncompany_location                     True\nreview_date                          True\ncountry_of_bean_origin               True\nspecific_bean_origin_or_bar_name     True\ncocoa_perc...\ncocoa_percent                        True\ncounts_of_ingredients                True\nbeans                               False\ncocoa_butter                        False\nvanilla                             False\nlecithin                            False\nsalt                                False\nsugar                               False\nsweetener_without_sugar             False\nfirst_taste                         False\nsecond_taste                        False\nthird_taste                         False\nfourth_taste                        False\ndtype: bool)])),\n                ('sfm',\n                 SelectFromModel(estimator=RandomForestRegressor(max_features='log2'),\n                                 max_features=450)),\n                ('ridge', Ridge(alpha=2.7825594022071245))])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00014-ec2b58d7-ad7c-42a9-9247-5e4b48123928",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "5dbe30cf",
        "execution_millis": 38,
        "execution_start": 1615576971445,
        "deepnote_cell_type": "code"
      },
      "source": "# model performance on test data\n# using R2 to measure the percentage of variance in the target explained by the model\n# because using MAE we can compare how two model is performing but harder to tell how \n# one model is performing\nprint('R2 score: ', final_ridge_pipe.score(X_test, y_test))",
      "execution_count": 23,
      "outputs": [
        {
          "name": "stdout",
          "text": "R2 score:  0.3406171493333361\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "# Conclusion",
      "metadata": {
        "tags": [],
        "cell_id": "00016-7bc5af31-f75d-4402-bd29-bb2618d21faa",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00015-52740a30-d1e8-4b5f-8532-2f1a8f548e39",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "7f4f44c8",
        "execution_millis": 71,
        "execution_start": 1615477930487,
        "deepnote_cell_type": "code"
      },
      "source": "# retrieving the name of the feature selected\ncategorical_feature_names = final_ridge_pipe['preprocessing'].named_transformers_['categorical']['ohe'].get_feature_names().tolist()\nfeature_names = np.array(categorical_feature_names + list(categorical_columns[categorical_columns==False].index))\n\nfeature_idx = final_ridge_pipe['sfm'].get_support()\nselected_features = feature_names[feature_idx]",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00015-2c01f19e-dc38-4666-b01a-cc8424200d2f",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "93654c63",
        "execution_millis": 47,
        "execution_start": 1615477931421,
        "deepnote_cell_type": "code"
      },
      "source": "# checking which variables are used\nvariable_index = set(int(i.split('_')[0].replace('x', '')) for i in selected_features[:-8])\nprint('Params used in model: ')\nfor idx in variable_index:\n    name = categorical_columns[categorical_columns].index[idx]\n    print('CAT - ', idx, '-', name)\nfor feature in selected_features[-2:]:\n    print('CON - ', feature)",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Params used in model: \nCAT -  0 - company\nCAT -  1 - company_location\nCAT -  2 - review_date\nCAT -  3 - country_of_bean_origin\nCAT -  4 - specific_bean_origin_or_bar_name\nCAT -  6 - cocoa_butter\nCAT -  7 - vanilla\nCAT -  8 - lecithin\nCAT -  9 - salt\nCAT -  10 - sugar\nCAT -  11 - sweetener_without_sugar\nCAT -  12 - first_taste\nCAT -  13 - second_taste\nCAT -  14 - third_taste\nCAT -  15 - fourth_taste\nCON -  cocoa_percent\nCON -  counts_of_ingredients\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "cell_id": "00017-5ddb3a33-f868-427c-a8b1-db5599488818",
        "deepnote_to_be_reexecuted": false,
        "source_hash": "a39c3bf3",
        "execution_millis": 12,
        "execution_start": 1615343922351,
        "deepnote_cell_type": "code"
      },
      "source": "# checking the top 10 biggest coeeficient\nsorted(zip(selected_features, final_ridge_pipe['ridge'].coef_), key=lambda x: -np.abs(x[1]))[:10]",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 186,
          "data": {
            "text/plain": "[('x14_very bitter', -0.4956080384492338),\n ('x13_medicinal', -0.4230425478907575),\n ('x12_pastey', -0.3651514109881082),\n ('x4_Dark', -0.3647776843397996),\n ('x0_Madecasse (Cinagra)', 0.35825182510445275),\n ('x13_pungent', -0.32992480474533176),\n ('x12_burnt rubber', -0.31631653286007416),\n ('x13_strong chemical', -0.31442311268972994),\n ('x12_perfume', -0.30604120029818793),\n ('x13_dirty', -0.3019164666372393)]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "\nThe top 10 coefficients are mostly from the taste test which makes sense since the rating is an objective score. It it very interesting that they can taste `burnt rubber`, `dirty`, `pungent` from chocolate and reasonably these taste impacted the rating negatively. `x0_Madecasse (Cinagra)` is the name of a company and the chocolate being that brand impacts the score positively, so perhaps it's a chocolate brand to one might want to try out.\n\nBased on the coefficients, it seems like taste test are very directly correlated with the score that the biggest coefficient does not involve other features of chocolate (e.g. kind of beans, cocoa content). One challenge of this data set is that many of the columns contains data that holds a lot of meaning (e.g. taste test) that one hot encoding is not able to capture, hence we only have a R^2 score of 0.3. An interesting next step another step would be to use custom word embedding to better encode this dataset to study the relationship between features of chocolate and the flavor graders taste and hence the rating.\n\nThis information could potentially be useful in reducing the cost to develop new and tasty chocolates, by simply predicting the rating of the chocolate from the ingredients they are using. It could also benefits consumers in a way where we can avoid bad tasting chocolate with taste like `burnt rubber` and `dirty` and save our money for amazing chocolates.",
      "metadata": {
        "tags": [],
        "cell_id": "00018-7f7af983-3fca-49c6-ae2a-7ab0972ba789",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": "",
      "metadata": {
        "tags": [],
        "cell_id": "00019-25de0a56-de8b-455f-a46c-07b2ba5f42df",
        "deepnote_cell_type": "markdown"
      }
    },
    {
      "cell_type": "markdown",
      "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=15c88ccc-0e75-46fc-8561-25080a52c07c' target=\"_blank\">\n<img style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0iVVRGLTgiPz4KPHN2ZyB3aWR0aD0iODBweCIgaGVpZ2h0PSI4MHB4IiB2aWV3Qm94PSIwIDAgODAgODAiIHZlcnNpb249IjEuMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB4bWxuczp4bGluaz0iaHR0cDovL3d3dy53My5vcmcvMTk5OS94bGluayI+CiAgICA8IS0tIEdlbmVyYXRvcjogU2tldGNoIDU0LjEgKDc2NDkwKSAtIGh0dHBzOi8vc2tldGNoYXBwLmNvbSAtLT4KICAgIDx0aXRsZT5Hcm91cCAzPC90aXRsZT4KICAgIDxkZXNjPkNyZWF0ZWQgd2l0aCBTa2V0Y2guPC9kZXNjPgogICAgPGcgaWQ9IkxhbmRpbmciIHN0cm9rZT0ibm9uZSIgc3Ryb2tlLXdpZHRoPSIxIiBmaWxsPSJub25lIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiPgogICAgICAgIDxnIGlkPSJBcnRib2FyZCIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoLTEyMzUuMDAwMDAwLCAtNzkuMDAwMDAwKSI+CiAgICAgICAgICAgIDxnIGlkPSJHcm91cC0zIiB0cmFuc2Zvcm09InRyYW5zbGF0ZSgxMjM1LjAwMDAwMCwgNzkuMDAwMDAwKSI+CiAgICAgICAgICAgICAgICA8cG9seWdvbiBpZD0iUGF0aC0yMCIgZmlsbD0iIzAyNjVCNCIgcG9pbnRzPSIyLjM3NjIzNzYyIDgwIDM4LjA0NzY2NjcgODAgNTcuODIxNzgyMiA3My44MDU3NTkyIDU3LjgyMTc4MjIgMzIuNzU5MjczOSAzOS4xNDAyMjc4IDMxLjY4MzE2ODMiPjwvcG9seWdvbj4KICAgICAgICAgICAgICAgIDxwYXRoIGQ9Ik0zNS4wMDc3MTgsODAgQzQyLjkwNjIwMDcsNzYuNDU0OTM1OCA0Ny41NjQ5MTY3LDcxLjU0MjI2NzEgNDguOTgzODY2LDY1LjI2MTk5MzkgQzUxLjExMjI4OTksNTUuODQxNTg0MiA0MS42NzcxNzk1LDQ5LjIxMjIyODQgMjUuNjIzOTg0Niw0OS4yMTIyMjg0IEMyNS40ODQ5Mjg5LDQ5LjEyNjg0NDggMjkuODI2MTI5Niw0My4yODM4MjQ4IDM4LjY0NzU4NjksMzEuNjgzMTY4MyBMNzIuODcxMjg3MSwzMi41NTQ0MjUgTDY1LjI4MDk3Myw2Ny42NzYzNDIxIEw1MS4xMTIyODk5LDc3LjM3NjE0NCBMMzUuMDA3NzE4LDgwIFoiIGlkPSJQYXRoLTIyIiBmaWxsPSIjMDAyODY4Ij48L3BhdGg+CiAgICAgICAgICAgICAgICA8cGF0aCBkPSJNMCwzNy43MzA0NDA1IEwyNy4xMTQ1MzcsMC4yNTcxMTE0MzYgQzYyLjM3MTUxMjMsLTEuOTkwNzE3MDEgODAsMTAuNTAwMzkyNyA4MCwzNy43MzA0NDA1IEM4MCw2NC45NjA0ODgyIDY0Ljc3NjUwMzgsNzkuMDUwMzQxNCAzNC4zMjk1MTEzLDgwIEM0Ny4wNTUzNDg5LDc3LjU2NzA4MDggNTMuNDE4MjY3Nyw3MC4zMTM2MTAzIDUzLjQxODI2NzcsNTguMjM5NTg4NSBDNTMuNDE4MjY3Nyw0MC4xMjg1NTU3IDM2LjMwMzk1NDQsMzcuNzMwNDQwNSAyNS4yMjc0MTcsMzcuNzMwNDQwNSBDMTcuODQzMDU4NiwzNy43MzA0NDA1IDkuNDMzOTE5NjYsMzcuNzMwNDQwNSAwLDM3LjczMDQ0MDUgWiIgaWQ9IlBhdGgtMTkiIGZpbGw9IiMzNzkzRUYiPjwvcGF0aD4KICAgICAgICAgICAgPC9nPgogICAgICAgIDwvZz4KICAgIDwvZz4KPC9zdmc+' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
      "metadata": {
        "tags": [],
        "created_in_deepnote_cell": true,
        "deepnote_cell_type": "markdown"
      }
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "orig_nbformat": 2,
    "deepnote_notebook_id": "2e97ed33-acd4-4575-8b60-f30118fce351",
    "deepnote": {
      "is_reactive": false
    },
    "deepnote_execution_queue": []
  }
}